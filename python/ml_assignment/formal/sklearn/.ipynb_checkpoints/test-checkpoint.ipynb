{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b99168f-e0dc-463e-a134-349e69ae884e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-574547c23c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Combined with the sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "import time\n",
    "import loader\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 1024\n",
    "classes = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "train_inputs, train_output= loader.load_data_sklearn()\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_inputs, train_output, test_size=0.2, random_state=2021)\n",
    "\n",
    "## normalized\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(X_train)\n",
    "test_X = scaler.transform(X_test)\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output, dropout=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.hidden_1 = torch.nn.Linear(n_feature, n_hidden)  # hidden layer\n",
    "        self.bn1 = torch.nn.BatchNorm1d(n_hidden)\n",
    "\n",
    "        self.hidden_2 = torch.nn.Linear(n_hidden, n_hidden//2)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(n_hidden//2)\n",
    "\n",
    "        self.hidden_3 = torch.nn.Linear(n_hidden//2, n_hidden//4)  # hidden layer\n",
    "        self.bn3 = torch.nn.BatchNorm1d(n_hidden//4)\n",
    "\n",
    "        self.hidden_4 = torch.nn.Linear(n_hidden // 4, n_hidden // 8)  # hidden layer\n",
    "        self.bn4 = torch.nn.BatchNorm1d(n_hidden // 8)\n",
    "\n",
    "        self.out = torch.nn.Linear(n_hidden//8, n_output)  # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden_1(x))  # activation function for hidden layer\n",
    "        x = self.dropout(self.bn1(x))\n",
    "        x = F.relu(self.hidden_2(x))  # activation function for hidden layer\n",
    "        x = self.dropout(self.bn2(x))\n",
    "        x = F.relu(self.hidden_3(x))  # activation function for hidden layer\n",
    "        x = self.dropout(self.bn3(x))\n",
    "        x = F.relu(self.hidden_4(x))  # activation function for hidden layer\n",
    "        x = self.dropout(self.bn4(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "NN_predictions = np.zeros((test_X.shape[0], ))\n",
    "oof_preds = np.zeros((train_X.shape[0], ))\n",
    "\n",
    "x_test = np.array(test_X)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float)\n",
    "if torch.cuda.is_available():\n",
    "    x_test = x_test.cuda()\n",
    "test = TensorDataset(x_test)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "avg_losses_f = []\n",
    "avg_val_losses_f = []\n",
    "\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(train_x)):\n",
    "    print(\"fold {}\".format(fold_ + 1))\n",
    "\n",
    "    x_train = Variable(torch.Tensor(train_X[trn_.astype(int)]))\n",
    "    y_train = Variable(torch.Tensor(train_y[trn_.astype(int), np.newaxis]))\n",
    "\n",
    "    x_valid = Variable(torch.Tensor(train_X[val_.astype(int)]))\n",
    "    y_valid = Variable(torch.Tensor(train_y[val_.astype(int), np.newaxis]))\n",
    "\n",
    "    model = MLP(x_train.shape[1], 20, classes, dropout=0.3)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        x_train, y_train = x_train.cuda(), y_train.cuda()\n",
    "        x_valid, y_valid = x_valid.cuda(), y_valid.cuda()\n",
    "        model = model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()  # Combined with the sigmoid\n",
    "\n",
    "    train = TensorDataset(x_train, y_train)\n",
    "    valid = TensorDataset(x_valid, y_valid)\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            y_pred = model(x_batch)\n",
    "\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()       # clear gradients for next train\n",
    "            loss.backward()             # -> accumulates the gradient (by addition) for each parameter\n",
    "            optimizer.step()            # -> update weights and biases\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "            # avg_auc += round(roc_auc_score(y_batch.cpu(),y_pred.detach().cpu()),4) / len(train_loader)\n",
    "        model.eval()\n",
    "\n",
    "        valid_preds_fold = np.zeros((x_valid.size(0)))\n",
    "        test_preds_fold = np.zeros((len(test_X)))\n",
    "\n",
    "        avg_val_loss = 0.\n",
    "        # avg_val_auc = 0.\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "            y_pred = model(x_batch).detach()\n",
    "\n",
    "            # avg_val_auc += round(roc_auc_score(y_batch.cpu(),sigmoid(y_pred.cpu().numpy())[:, 0]),4) / len(valid_loader)\n",
    "            avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "            valid_preds_fold[i * batch_size:(i + 1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(epoch + 1, epochs, avg_loss, avg_val_loss, elapsed_time))\n",
    "\n",
    "    avg_losses_f.append(avg_loss)\n",
    "    avg_val_losses_f.append(avg_val_loss)\n",
    "\n",
    "    for i, (x_batch,) in enumerate(test_loader):\n",
    "        y_pred = model(x_batch).detach()\n",
    "\n",
    "        test_preds_fold[i * batch_size:(i + 1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "\n",
    "    oof_preds[val_] = valid_preds_fold\n",
    "    NN_predictions += test_preds_fold / folds.n_splits\n",
    "\n",
    "auc = round(roc_auc_score(train_y, oof_preds), 4)\n",
    "print('All \\t loss={:.4f} \\t val_loss={:.4f} \\t auc={:.4f}'.format(np.average(avg_losses_f), np.average(avg_val_losses_f), auc))\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb59a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
